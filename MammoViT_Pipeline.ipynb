{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f5489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from src.data_loading.torch_data_utils import load_data_with_logging\n",
    "from src.models.residual_preprocess import PreprocessingResidual\n",
    "from src.models.resnet50 import ResNet\n",
    "from src.prep_and_processing.processing_utils import apply_smote, tensor_to_numpy, reshape_for_vit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e71ef6",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "This cell loads the data and prints the shape of training and validation batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d56ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch shape: torch.Size([32, 3, 224, 224])\n",
      "Validation batch shape: torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_dir = \"data/KAU\"\n",
    "dataloaders = load_data_with_logging(data_dir)\n",
    "\n",
    "# Print the shape of the training data\n",
    "images, labels = next(iter(dataloaders['train']))\n",
    "print(f\"Training batch shape: {images.shape}\")\n",
    "\n",
    "# Print the shape of the validation data\n",
    "images, labels = next(iter(dataloaders['val']))\n",
    "print(f\"Validation batch shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47928d8c",
   "metadata": {},
   "source": [
    "# Visualize Class Images\n",
    "This cell plots one image from each class in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb976e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get class names\n",
    "# class_names = dataloaders['train'].dataset.classes\n",
    "\n",
    "# # Plot one image from each class\n",
    "# fig, axes = plt.subplots(1, len(class_names), figsize=(15, 5))\n",
    "\n",
    "# for i, class_name in enumerate(class_names):\n",
    "#     found = False\n",
    "#     for images, labels in dataloaders['train']:\n",
    "#         mask = (labels == i).nonzero(as_tuple=True)[0]\n",
    "#         if mask.numel() > 0:\n",
    "#             idx = mask[0]\n",
    "#             image = images[idx].permute(1, 2, 0).numpy()\n",
    "#             image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]\n",
    "#             axes[i].imshow(image)\n",
    "#             axes[i].set_title(class_name)\n",
    "#             axes[i].axis('off')\n",
    "#             found = True\n",
    "#             break\n",
    "#     if not found:\n",
    "#         axes[i].set_title(f\"{class_name}\\n(Not Found)\")\n",
    "#         axes[i].axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d295be0",
   "metadata": {},
   "source": [
    "# Process Data Using PreprocessingResidual\n",
    "This cell initializes the PreprocessingResidual class, processes the training images, applies a linear projection, and prints the shape of the projected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e9b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected output shape: torch.Size([32, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the PreprocessingResidual stack\n",
    "cnn_processor = PreprocessingResidual()\n",
    "\n",
    "# Process the data using the Residual processor\n",
    "images, labels = next(iter(dataloaders['train']))\n",
    "processed_imgs = cnn_processor(images)\n",
    "\n",
    "# Apply linear projection\n",
    "projected_output = PreprocessingResidual.linear_projection(processed_imgs.size(1), processed_imgs)\n",
    "\n",
    "# Print the shape of the projected output\n",
    "print(f\"Projected output shape: {projected_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8165a36",
   "metadata": {},
   "source": [
    "# Feature Extraction Using ResNet Layer\n",
    "This cell uses ResNet layer to preprocess images to better extract features for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf242b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: torch.Size([32, 2048, 7, 7])\n",
      "Pooled features shape: torch.Size([32, 2048])\n"
     ]
    }
   ],
   "source": [
    "featureExtractor = ResNet().get_model()\n",
    "\n",
    "# Permute needed for [B, 3,224,224] shape model expects\n",
    "projected_output = projected_output.permute(0, 3, 1, 2)\n",
    "\n",
    "# Extract features from the processed images\n",
    "extracted_features = featureExtractor(projected_output)\n",
    "\n",
    "# Perform global average pooling\n",
    "pooled_features = ResNet.global_average_pooling(extracted_features)\n",
    "\n",
    "# Print the shape of extracted features\n",
    "print(f\"Extracted features shape: {extracted_features.shape}\")\n",
    "\n",
    "# Print the shape of pooled features\n",
    "print(f\"Pooled features shape: {pooled_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172a9e8",
   "metadata": {},
   "source": [
    "# Apply SMOTE to Oversample Features and Labels\n",
    "This cell applies the SMOTE function to oversample features and labels, and prints their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89e1757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled features shape: (40, 2048)\n",
      "Oversampled labels shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "pooled_features_np = tensor_to_numpy(pooled_features)\n",
    "labels_np = tensor_to_numpy(labels)\n",
    "\n",
    "# Apply SMOTE to oversample features and labels\n",
    "oversampled_features, oversampled_labels = apply_smote(pooled_features_np, labels_np)\n",
    "\n",
    "# Print the shape of the oversampled features and labels\n",
    "print(f\"Oversampled features shape: {oversampled_features.shape}\")\n",
    "print(f\"Oversampled labels shape: {oversampled_labels.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MammoViT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
