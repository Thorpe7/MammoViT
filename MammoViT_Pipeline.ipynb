{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from src.data_loading.torch_data_utils import load_data_with_logging\n",
    "from models.residual_preprocess import PreprocessingResidual\n",
    "from src.models.resnet50 import ResNet\n",
    "from src.prep_and_processing.processing_utils import reshape_for_vit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e71ef6",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "This cell loads the data and prints the shape of training and validation batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d56ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch shape: torch.Size([32, 3, 224, 224])\n",
      "Validation batch shape: torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_dir = \"data/KAU\"\n",
    "dataloaders = load_data_with_logging(data_dir)\n",
    "\n",
    "# Print the shape of the training data\n",
    "images, labels = next(iter(dataloaders['train']))\n",
    "print(f\"Training batch shape: {images.shape}\")\n",
    "\n",
    "# Print the shape of the validation data\n",
    "images, labels = next(iter(dataloaders['val']))\n",
    "print(f\"Validation batch shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47928d8c",
   "metadata": {},
   "source": [
    "# Visualize Class Images\n",
    "This cell plots one image from each class in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb976e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = dataloaders['train'].dataset.classes\n",
    "\n",
    "# Plot one image from each class\n",
    "fig, axes = plt.subplots(1, len(class_names), figsize=(15, 5))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    found = False\n",
    "    for images, labels in dataloaders['train']:\n",
    "        mask = (labels == i).nonzero(as_tuple=True)[0]\n",
    "        if mask.numel() > 0:\n",
    "            idx = mask[0]\n",
    "            image = images[idx].permute(1, 2, 0).numpy()\n",
    "            image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].set_title(class_name)\n",
    "            axes[i].axis('off')\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        axes[i].set_title(f\"{class_name}\\n(Not Found)\")\n",
    "        axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d295be0",
   "metadata": {},
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected output shape: torch.Size([32, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the PreprocessinResidual\n",
    "cnn_processor = PreprocessingResidual()\n",
    "\n",
    "# Process the data using the Residual processor\n",
    "images, labels = next(iter(dataloaders['train']))\n",
    "processed_imgs = cnn_processor(images)\n",
    "\n",
    "# Apply linear projection\n",
    "projected_output = PreprocessingResidual.linear_projection(processed_imgs.size(1), processed_imgs)\n",
    "\n",
    "# Print the shape of the projected output\n",
    "print(f\"Projected output shape: {projected_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8165a36",
   "metadata": {},
   "source": [
    "# Feature Extraction Using ResNet Layer\n",
    "This cell uses ResNet layer to preprocess images to better extract features for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf242b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: torch.Size([32, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "featureExtractor = ResNet().get_model()\n",
    "\n",
    "# Permute projected_output to match ResNet input shape\n",
    "projected_output = projected_output.permute(0, 3, 1, 2)\n",
    "\n",
    "# Extract features from the processed images\n",
    "extracted_features = featureExtractor(projected_output)\n",
    "\n",
    "# Print the shape of extracted features\n",
    "print(f\"Extracted features shape: {extracted_features.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MammoViT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
